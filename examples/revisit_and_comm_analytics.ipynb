{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook analyzes the results of an \"observer\" agent group and a \"target\" agent group from a simulation and produces plots to visualize the revisit and data handling behavior between them. To understand the required user inputs, read the [Analysis Configuration](#analysis-configuration) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "This notebook produces the following plots:\n",
    "\n",
    "- Revisit\n",
    "  - [Revisit Timeline](#revisit-timeline)\n",
    "  - [Revisit Duration Distribution](#revisit-duration-distribution)\n",
    "- Data Transmit\n",
    "  - [Transmit Bit Rate by Agent](#transmit-bit-rate-by-agent)\n",
    "  - [Transmit Bit Rate by Target](#transmit-bit-rate-by-target)\n",
    "  - [Transmit Bit Rate by Data Type](#transmit-bit-rate-by-data-type)\n",
    "  - [Cumulative Data Transmitted by Agent](#cumulative-data-transmitted-by-agent)\n",
    "  - [Cumulative Data Transmitted by Target](#cumulative-data-transmitted-by-target)\n",
    "  - [Cumulative Data Transmitted by Data Type](#cumulative-data-transmitted-by-data-type)\n",
    "  - [Cumulative Data Transmitted to All Targets](#cumulative-data-transmitted-to-all-targets)\n",
    "- Data Receive\n",
    "  - [Receive Bit Rate by Agent](#receive-bit-rate-by-agent)\n",
    "  - [Receive Bit Rate by Target](#receive-bit-rate-by-target)\n",
    "  - [Receive Bit Rate by Data Type](#receive-bit-rate-by-data-type)\n",
    "  - [Cumulative Data Received by Agent](#cumulative-data-received-by-agent)\n",
    "  - [Cumulative Data Received by Target](#cumulative-data-received-by-target)\n",
    "  - [Cumulative Data Received by Data Type](#cumulative-data-received-by-data-type)\n",
    "  - [Cumulative Data Received to All Targets](#cumulative-data-received-from-all-targets)\n",
    "- Data Storage\n",
    "  - [Total Data Storage Usage by Agent](#total-data-storage-usage-by-agent)\n",
    "  - [Total Data Storage Usage by all Agents](#total-data-storage-usage-by-all-agents)\n",
    "  - [Data Storage Usage by Data Type](#data-storage-usage-by-data-type)\n",
    "  - [Data Minimum, Maximum, and Average Age by Agent](#data-minimum-maximum-and-average-age-by-agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package Installation and Import\n",
    "\n",
    "The following cell should install all necessary packages for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas plotly IPython ipywidgets nbformat\n",
    "%pip install \"sedaro>=4.16.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from itertools import groupby\n",
    "from math import floor, log10\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import IntProgress\n",
    "from sedaro import SedaroAgentResult, SedaroApiClient\n",
    "from sedaro.modsim import mjd_to_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Read Before Running\n",
    "\n",
    "This notebook requires that you have previously generated an API key in the web UI. That key should be stored in a file called `secrets.json` in the cloned `modsim-notebooks` directory with the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"API_KEY\": \"<API_KEY>\"\n",
    "}\n",
    "```\n",
    "\n",
    "API keys grant full access to your repositories and should never be shared. If you think your API key has been compromised, you can revoke it in the user settings interface on the Sedaro website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../secrets.json', 'r') as file:\n",
    "    API_KEY = json.load(file)['API_KEY']\n",
    "\n",
    "with open('../config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "HOST = config['HOST']  # Sedaro instance URL\n",
    "\n",
    "sedaro = SedaroApiClient(API_KEY, HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Configuration\n",
    "\n",
    "Below are fields that point the notebook to simulation data and drive analysis behavior.\n",
    "- `SCENARIO_BRANCH_ID`: The branch ID of the scenario that you would like to analyze.\n",
    "- `JOB_ID`: An optional field for the ID of the specific simulation job that you would like to analyze. If left as an empty string (`\"\"`), the most recent simulation from your Scenario will be analyzed.\n",
    "- `OBSERVER_AGENT_GROUP_ID`: The ID of the agent group that contains the agents that revisited, transmitted data to, and/or received data from the agents in the target agent group.\n",
    "- `TARGET_AGENT_GROUP_ID`: The ID of the target agent group that contains the agents that were revisited by, transmitted data to, and/or received data from the agents in the observer agent group.\n",
    "- `REVISIT_ANALYSIS`: Whether to perform revisit analysis from the observer agent group to the target agent group.\n",
    "- `REVISIT_ANALYSIS_CONDITION`: The name of the condition that is met when an observer agent revisits a target agent. There must be a `TargetGroupCondition` with this name on each of the observer agent templates.\n",
    "- `DATA_ANALYSIS`: Whether to perform data analysis for the observer agent group and between the observer agent group and the target agent group.\n",
    "- `DATA_ANALYSIS_DATA_TYPES`: The names of the data types that should be considered for data analysis. Data types that are not in this list will not affect data analysis results. If the list is empty, all data types will be considered.\n",
    "- `px.defaults.template`: Set to `\"plotly_dark\"` for dark themed plots or `\"plotly_white\"` for light themed plots.\n",
    "\n",
    "The fields are already filled with values that point towards [the Wildfire demo in the Sedaro Shared Demos workspace](https://satellite.sedaro.com/projects/PKCbxBlcdpFkvHxfKKRKqT). These will allow you to run this notebook without further configuration if you have an account with a valid API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO_BRANCH_ID: str = \"PKCbxCXvQhCn8glwd5mkSj\"  # ID of the Scenario branch\n",
    "JOB_ID: str = \"\"  # optional ID of the simulation job\n",
    "\n",
    "OBSERVER_AGENT_GROUP_ID: str = \"NT08_XVROe2Va_eBgCK2k\"  # ID of the observer AgentGroup\n",
    "TARGET_AGENT_GROUP_ID: str = \"NTKAJurTrHOKg99QP6Hpk\"  # ID of the target AgentGroup\n",
    "\n",
    "\n",
    "REVISIT_ANALYSIS: bool = True  # if True, the revisit analysis will be performed\n",
    "REVISIT_ANALYSIS_CONDITION: str = \"Ground Station Elevation Angle\"  # name of the condition that indicates a revisit\n",
    "\n",
    "DATA_ANALYSIS: bool = True  # if True, the data analysis will be performed\n",
    "DATA_ANALYSIS_DATA_TYPES: list[str] = []  # names of the data types to include in the analysis, empty list includes all\n",
    "\n",
    "px.defaults.template = \"plotly_dark\"\n",
    "# px.defaults.template = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = sedaro.scenario(SCENARIO_BRANCH_ID)\n",
    "\n",
    "observer_agents = list(scenario.AgentGroup.get(OBSERVER_AGENT_GROUP_ID).agentAssociations.keys())\n",
    "target_agents = list(scenario.AgentGroup.get(TARGET_AGENT_GROUP_ID).agentAssociations.keys())\n",
    "# ^^^ this will get us the names for targets created during build to populate a TG, but not for targets which exist on\n",
    "# the model\n",
    "observer_to_target_mapping = defaultdict(dict)\n",
    "for observer_agent in observer_agents:\n",
    "    for agent_data, mapping_data in observer_agent.targetMapping.items():\n",
    "        for target_id in mapping_data['associatedTargets']:\n",
    "            observer_to_target_mapping[observer_agent.name][target_id] = agent_data.id\n",
    "observer_to_target_mapping = dict(observer_to_target_mapping) # default behavior ok for population, missing key should error below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scenario.simulation.results(JOB_ID)\n",
    "\n",
    "observer_results = {agent.name: results.agent(agent.name) for agent in observer_agents}\n",
    "\n",
    "results.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisit Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_revisit_results(\n",
    "    observer_results: dict[str, SedaroAgentResult],\n",
    "    revisit_condition_ids: dict[str, str],\n",
    "    target_names_by_id: dict[str, str],\n",
    "    observer_to_target_mapping: dict[str, dict[str, str]],\n",
    "    progress_bar: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    if progress_bar:\n",
    "        bar = IntProgress(min=0, max=len(observer_results), layout={'width': '100%'})\n",
    "        display(bar)\n",
    "\n",
    "    revisits: list[dict[str, datetime | str]] = []\n",
    "    for agent, agent_results in observer_results.items():\n",
    "        condition_compliance_results = agent_results.block(revisit_condition_ids[agent]).targetCompliance\n",
    "        compliance_values: dict[str, list[bool]] = condition_compliance_results.values\n",
    "        compliance_times = [mjd_to_datetime(t) for t in condition_compliance_results.mjd]\n",
    "        for target_id, compliance_series in compliance_values.items():\n",
    "            for compliance, group in groupby(enumerate(compliance_series), key=lambda x: x[1]):\n",
    "                if compliance:\n",
    "                    revisit_indices: list[int] = [index for index, _ in group]\n",
    "                    if revisit_indices[-1] < len(compliance_series) - 1:\n",
    "                        revisit_indices.append(revisit_indices[-1] + 1)\n",
    "                    revisit_start_time = compliance_times[revisit_indices[0]]\n",
    "                    revisit_end_time = compliance_times[revisit_indices[-1]]\n",
    "                    agent_id = observer_to_target_mapping[agent].get(target_id, target_id)\n",
    "                    revisits.append({\n",
    "                        \"Agent\": agent,\n",
    "                        \"Target\": target_names_by_id[agent_id],\n",
    "                        \"Start\": revisit_start_time,\n",
    "                        \"End\": revisit_end_time,\n",
    "                        \"Duration\": revisit_end_time - revisit_start_time\n",
    "                    })\n",
    "\n",
    "        if progress_bar:\n",
    "            bar.value += 1\n",
    "\n",
    "    return pd.DataFrame(revisits)\n",
    "\n",
    "\n",
    "def target_revisit_statistics(\n",
    "    revisits: pd.DataFrame,\n",
    "    progress_bar: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    unique_targets = revisits[\"Target\"].unique()\n",
    "    if progress_bar:\n",
    "        bar = IntProgress(min=0, max=len(unique_targets) + 1, layout={'width': '100%'})\n",
    "        display(bar)\n",
    "\n",
    "    revisits.sort_values(by=[\"Start\", \"End\"], inplace=True)\n",
    "    revisit_statistics: list[dict[str, float]] = []\n",
    "    for target in unique_targets:\n",
    "        target_revisits: pd.DataFrame = revisits[revisits[\"Target\"] == target]\n",
    "        if not target_revisits.empty:\n",
    "            revisit_statistics.append({\n",
    "                \"Target\": target,\n",
    "                \"Average Duration\": target_revisits[\"Duration\"].mean(),\n",
    "                \"Total Duration\": target_revisits[\"Duration\"].sum(),\n",
    "                \"Number of Revisits\": target_revisits[\"Duration\"].count(),\n",
    "                \"Min. Time Between Revisits\": target_revisits[\"Start\"].diff().min(),\n",
    "                \"Max. Time Between Revisits\": target_revisits[\"Start\"].diff().max(),\n",
    "            })\n",
    "\n",
    "        if progress_bar:\n",
    "            bar.value += 1\n",
    "\n",
    "    revisit_statistics.append({\n",
    "        \"Target\": \"Total\",\n",
    "        \"Average Duration\": revisits[\"Duration\"].mean(),\n",
    "        \"Total Duration\": revisits[\"Duration\"].sum(),\n",
    "        \"Number of Revisits\": revisits[\"Duration\"].count(),\n",
    "        \"Min. Time Between Revisits\": revisits[\"Start\"].diff().min(),\n",
    "        \"Max. Time Between Revisits\": revisits[\"Start\"].diff().max(),\n",
    "    })\n",
    "\n",
    "    if progress_bar:\n",
    "        bar.value += 1\n",
    "\n",
    "    return pd.DataFrame(revisit_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_data_results(\n",
    "    agent_templates: dict[str, Any],\n",
    "    observer_results: dict[str, SedaroAgentResult],\n",
    "    target_names_by_id: dict[str, str],\n",
    "    select_data_types: list[str] = [],\n",
    "    progress_bar: bool = True,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    if progress_bar:\n",
    "        bar = IntProgress(min=0, max=len(observer_results), layout={'width': '100%'})\n",
    "        display(bar)\n",
    "\n",
    "    transmit_data: list[dict[str, float]] = []\n",
    "    receive_data: list[dict[str, float]] = []\n",
    "    data_storage_data: list[dict[str, float]] = []\n",
    "    for agent, agent_template in agent_templates.items():\n",
    "        agent_results = observer_results[agent]\n",
    "        results_times_mjd = agent_results.block(agent_template.Routine.get_first().id).isActive.mjd\n",
    "        results_times = [mjd_to_datetime(t) for t in results_times_mjd]\n",
    "\n",
    "        for data_interface in agent_template.TransmitInterface.get_all():\n",
    "            data_interface_results = agent_results.block(data_interface.id)\n",
    "            valid_data_type_names = [data_type.name for data_type in data_interface.dataTypes.keys()\n",
    "                                     if not select_data_types or data_type.name in select_data_types]\n",
    "            for data_type_name in valid_data_type_names:\n",
    "                for target, bit_rate, t_1, t_2 in zip(data_interface_results.activeLinkTarget.values, data_interface_results.typeBitRates.values[data_type_name], results_times, results_times[1:]):\n",
    "                    if target in target_names_by_id:\n",
    "                        transmit_data.append({\n",
    "                            \"Time\": t_1,\n",
    "                            \"Bit Rate\": bit_rate,\n",
    "                            \"Data Transmitted\": bit_rate * (t_2 - t_1).total_seconds(),\n",
    "                            \"Data Type\": data_type_name,\n",
    "                            \"Agent\": agent,\n",
    "                            \"Target\": target_names_by_id[target],\n",
    "                        })\n",
    "\n",
    "        for data_interface in agent_template.ReceiveInterface.get_all():\n",
    "            data_interface_results = agent_results.block(data_interface.id)\n",
    "            for target, bit_rate, t_1, t_2 in zip(data_interface_results.activeLinkTarget.values, data_interface_results.bitRate.values, results_times, results_times[1:]):\n",
    "                if target in target_names_by_id:\n",
    "                    receive_data.append({\n",
    "                        \"Time\": t_1,\n",
    "                        \"Bit Rate\": bit_rate,\n",
    "                        \"Data Received\": bit_rate * (t_2 - t_1).total_seconds(),\n",
    "                        \"Data Type\": data_type_name,\n",
    "                        \"Agent\": agent,\n",
    "                        \"Target\": target_names_by_id[target],\n",
    "                    })\n",
    "\n",
    "        data_storage_ids = agent_template.DataStorage.get_all_ids()\n",
    "        valid_data_types = [data_type for data_type in agent_template.DataType.get_all()\n",
    "                            if not select_data_types or data_type.name in select_data_types]\n",
    "\n",
    "        usage_results_by_storage = {storage: agent_results.block(storage).usage.values for storage in data_storage_ids}\n",
    "        avg_data_age_results_by_storage = {storage: agent_results.block(storage).averageDataAge.values\n",
    "                                           for storage in data_storage_ids}\n",
    "        min_data_age_results_by_storage = {storage: agent_results.block(storage).minDataAge.values\n",
    "                                           for storage in data_storage_ids}\n",
    "        max_data_age_results_by_storage = {storage: agent_results.block(storage).maxDataAge.values\n",
    "                                           for storage in data_storage_ids}\n",
    "        for n, t in enumerate(results_times):\n",
    "            for data_type in valid_data_types:\n",
    "                for storage in data_storage_ids:\n",
    "                    data_storage_data.append({\n",
    "                        \"Time\": t,\n",
    "                        \"Usage\": usage_results_by_storage[storage][data_type.id][n],\n",
    "                        \"Average Age\": avg_data_age_results_by_storage[storage][data_type.id][n],\n",
    "                        \"Min. Age\": min_data_age_results_by_storage[storage][data_type.id][n],\n",
    "                        \"Max. Age\": max_data_age_results_by_storage[storage][data_type.id][n],\n",
    "                        \"Data Type\": data_type.name,\n",
    "                        \"Agent\": agent,\n",
    "                    })\n",
    "\n",
    "        if progress_bar:\n",
    "            bar.value += 1\n",
    "\n",
    "    transmit_dataframe = pd.DataFrame(\n",
    "        transmit_data, columns=[\"Time\", \"Bit Rate\", \"Data Transmitted\", \"Data Type\", \"Agent\", \"Target\"])\n",
    "    transmit_dataframe.fillna(0, inplace=True)\n",
    "    receive_dataframe = pd.DataFrame(receive_data, columns=[\"Time\", \"Bit Rate\", \"Data Received\", \"Agent\", \"Target\"])\n",
    "    receive_dataframe.fillna(0, inplace=True)\n",
    "    data_storage_dataframe = pd.DataFrame(data_storage_data, columns=[\n",
    "                                          \"Time\", \"Usage\", \"Average Age\", \"Min. Age\", \"Max. Age\", \"Data Type\", \"Agent\"])\n",
    "    return transmit_dataframe, receive_dataframe, data_storage_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REVISIT_ANALYSIS or DATA_ANALYSIS:\n",
    "    observer_template_branches = {template_ref: sedaro.agent_template(template_ref)\n",
    "                                  for template_ref in set(agent.templateRef for agent in observer_agents)}\n",
    "    observer_agent_templates = {agent.name: observer_template_branches[agent.templateRef]\n",
    "                                for agent in observer_agents}\n",
    "\n",
    "if REVISIT_ANALYSIS:\n",
    "    revisit_condition_ids = {}\n",
    "    for agent_name, agent_template in observer_agent_templates.items():\n",
    "        revisit_condition_id = next((condition.id for condition in agent_template.TargetGroupCondition.get_all()\n",
    "                                     if condition.name == REVISIT_ANALYSIS_CONDITION), None)\n",
    "        if revisit_condition_id is None:\n",
    "            raise ValueError(\n",
    "                f\"The revisit analysis condition ({REVISIT_ANALYSIS_CONDITION}) is not present in the agent template for {agent_name}.\")\n",
    "        revisit_condition_ids[agent_name] = revisit_condition_id\n",
    "    target_revisits = target_revisit_results(observer_results, revisit_condition_ids,\n",
    "                                             {target.id: target.name for target in target_agents}, observer_to_target_mapping)\n",
    "    revisit_statistics = target_revisit_statistics(target_revisits)\n",
    "\n",
    "if DATA_ANALYSIS:\n",
    "    transmit_data_results, receive_data_results, data_storage_results = target_data_results(\n",
    "        observer_agent_templates, observer_results, {target.id: target.name for target in target_agents}, DATA_ANALYSIS_DATA_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data_units(value: float, bytes: bool = False) -> tuple[float, str]:\n",
    "    \"\"\"\n",
    "    Find the appropriate unit to scale the given value and return the scale along with the unit string.\n",
    "\n",
    "    Args:\n",
    "        value (float): The value to be scaled.\n",
    "        bytes (bool): Whether to convert the value to bytes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the scale and the unit string.\n",
    "    \"\"\"\n",
    "    units = [\"\", \"k\", \"M\", \"G\", \"T\", \"P\"]\n",
    "    if value == 0:\n",
    "        return value, \"\"\n",
    "    value = value if not bytes else value / 8\n",
    "    exponent = floor(log10(abs(value)) // 3)\n",
    "    scale: int = (10 ** (exponent * 3))\n",
    "    scale = scale if not bytes else scale * 8\n",
    "    unit = units[exponent]\n",
    "    return scale, unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisit Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REVISIT_ANALYSIS:\n",
    "    fig = px.timeline(target_revisits, x_start=\"Start\", x_end=\"End\",\n",
    "                      y=\"Target\", color=\"Agent\", title=\"Revisit Timeline\")\n",
    "    fig.show()\n",
    "    display(HTML(revisit_statistics.to_html(index=False)))\n",
    "else:\n",
    "    print(\"No revisit analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisit Duration Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REVISIT_ANALYSIS:\n",
    "    revisit_distribution_results = target_revisits.copy(deep=True)\n",
    "    # convert durations to datetime for plotly formatting\n",
    "    revisit_distribution_results.Duration = revisit_distribution_results.Duration + pd.to_datetime(\"1970-01-01\")\n",
    "    fig = px.violin(revisit_distribution_results, x=\"Target\", y=\"Duration\",\n",
    "                    box=True, title=\"Revisit Duration Distribution\")\n",
    "    fig.update_yaxes(tickformat=\"%M:%S\", title=\"Duration (MM:SS)\")\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No revisit analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transmit Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmit Bit Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transmit Bit Rate by Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.groupby([\"Time\", \"Agent\"])[\"Bit Rate\"].sum().reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Bit Rate\", color=\"Agent\", title=\"Transmit Bit Rate by Agent\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Bit Rate\"].max())\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Bit Rate ({unit_prefix}bps)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transmit Bit Rate by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.groupby([\"Time\", \"Target\"])[\"Bit Rate\"].sum().reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Bit Rate\", color=\"Target\", title=\"Transmit Bit Rate by Target\", line_shape=\"vh\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Bit Rate\"].max())\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Bit Rate ({unit_prefix}bps)\"))\n",
    "        fig.update_yaxes(tickformat=\".2s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transmit Bit Rate by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.groupby([\"Time\", \"Data Type\"]).sum().reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Bit Rate\", color=\"Data Type\",\n",
    "                      title=\"Transmit Bit Rate by Data Type\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Bit Rate\"].max())\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Bit Rate ({unit_prefix}bps)\"))\n",
    "        fig.update_yaxes(tickformat=\".2s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Data Transmitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Transmitted by Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Transmitted\"] = df.groupby(\"Agent\")[\"Data Transmitted\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Transmitted\", color=\"Agent\",\n",
    "                      title=\"Cumulative Data Transmitted by Agent\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Transmitted\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Transmitted ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Transmitted by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Transmitted\"] = df.groupby(\"Target\")[\"Data Transmitted\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Transmitted\", color=\"Target\",\n",
    "                      title=\"Cumulative Data Transmitted by Target\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Transmitted\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Transmitted ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Transmitted by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Transmitted\"] = df.groupby(\"Data Type\")[\"Data Transmitted\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Transmitted\",\n",
    "                      color=\"Data Type\", title=\"Cumulative Data Transmitted by Data Type\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Transmitted\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Transmitted ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Transmitted to All Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not transmit_data_results.empty:\n",
    "        df = transmit_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Transmitted\"] = df[\"Data Transmitted\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Transmitted\",\n",
    "                      title=\"Cumulative Data Transmitted to All Targets\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Transmitted\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale, fill='tozeroy'))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Transmitted ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No transmit data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Receive Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receive Bit Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receive Bit Rate by Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.groupby([\"Time\", \"Agent\"])[\"Bit Rate\"].sum().reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Bit Rate\", color=\"Agent\", title=\"Receive Bit Rate by Agent\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Bit Rate\"].max())\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Bit Rate ({unit_prefix}bps)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receive Bit Rate by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.groupby([\"Time\", \"Target\"])[\"Bit Rate\"].sum().reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Bit Rate\", color=\"Target\", title=\"Receive Bit Rate by Target\", line_shape=\"vh\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Bit Rate\"].max())\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Bit Rate ({unit_prefix}bps)\"))\n",
    "        fig.update_yaxes(tickformat=\".2s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receive Bit Rate by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.groupby([\"Time\", \"Data Type\"]).sum().reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Bit Rate\", color=\"Data Type\",\n",
    "                      title=\"Receive Bit Rate by Data Type\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Bit Rate\"].max())\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Bit Rate ({unit_prefix}bps)\"))\n",
    "        fig.update_yaxes(tickformat=\".2s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Data Received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Received by Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Received\"] = df.groupby(\"Agent\")[\"Data Received\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Received\", color=\"Agent\",\n",
    "                      title=\"Cumulative Data Received by Agent\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Received\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Received ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Received by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Received\"] = df.groupby(\"Target\")[\"Data Received\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Received\", color=\"Target\",\n",
    "                      title=\"Cumulative Data Received by Target\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Received\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Received ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Received by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Received\"] = df.groupby(\"Data Type\")[\"Data Received\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Received\",\n",
    "                      color=\"Data Type\", title=\"Cumulative Data Received by Data Type\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Received\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Received ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Data Received from All Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not receive_data_results.empty:\n",
    "        df = receive_data_results.sort_values(by=\"Time\")\n",
    "        df[\"Cumulative Data Received\"] = df[\"Data Received\"].cumsum()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Cumulative Data Received\",\n",
    "                      title=\"Cumulative Data Received to All Targets\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Cumulative Data Received\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale, fill='tozeroy'))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Cumulative Data Received ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No receive data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Data Storage Usage by Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not data_storage_results.empty:\n",
    "        df = pd.DataFrame(data_storage_results.groupby([\"Time\", \"Agent\"])[\"Usage\"].sum().reset_index())\n",
    "        fig = px.line(df, x=\"Time\", y=\"Usage\", color=\"Agent\",\n",
    "                      title=\"Total Data Storage Usage by Agent\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Usage\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Usage ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No data storage data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Data Storage Usage by All Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not data_storage_results.empty:\n",
    "        df = pd.DataFrame(data_storage_results.groupby(\"Time\")[\"Usage\"].sum()).reset_index()\n",
    "        df.rename(columns={\"Usage\": \"Total Usage\"}, inplace=True)\n",
    "        fig = px.line(df, x=\"Time\", y=\"Total Usage\", title=\"Total Data Storage Usage by All Agents\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Total Usage\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale, fill='tozeroy'))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Total Usage ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No data storage data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Storage Usage by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not data_storage_results.empty:\n",
    "        df = pd.DataFrame(data_storage_results.groupby([\"Time\", \"Data Type\"])[\"Usage\"].sum()).reset_index()\n",
    "        fig = px.line(df, x=\"Time\", y=\"Usage\", color=\"Data Type\",\n",
    "                      title=\"Total Data Storage Usage by Data Type\", line_shape=\"hv\")\n",
    "        scale, unit_prefix = scale_data_units(df[\"Usage\"].max(), bytes=True)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / scale))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Usage ({unit_prefix}B)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No data storage data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Minimum, Maximum, and Average Age by Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_ANALYSIS:\n",
    "    if not data_storage_results.empty:\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Time\"] = data_storage_results.groupby([\"Time\", \"Agent\"]).sum().reset_index()[\"Time\"]\n",
    "        df[\"Min. Age\"] = data_storage_results.groupby([\"Time\", \"Agent\"])[\"Min. Age\"].min().reset_index()[\"Min. Age\"]\n",
    "        df[\"Max. Age\"] = data_storage_results.groupby([\"Time\", \"Agent\"])[\"Max. Age\"].max().reset_index()[\"Max. Age\"]\n",
    "        df[\"Average Age\"] = data_storage_results.groupby([\"Time\", \"Agent\"]).apply(\n",
    "            lambda x: (x[\"Usage\"] * x[\"Average Age\"]).sum() / x[\"Usage\"].sum() if x[\"Usage\"].sum() != 0 else 0\n",
    "        ).reset_index(level=[0, 1], drop=True)\n",
    "        df[\"Agent\"] = data_storage_results.groupby([\"Time\", \"Agent\"]).first().reset_index()[\"Agent\"]\n",
    "        fig = px.line(df, x=\"Time\", y=[\"Min. Age\", \"Max. Age\"],\n",
    "                      color=\"Agent\", title=\"Data Minimum, Maximum, and Average Age by Agent\", line_shape=\"hv\")\n",
    "        fig.for_each_trace(lambda trace: trace.update(fill='tonexty', opacity=0.5,\n",
    "                                                      line={\"dash\": \"dot\"}, showlegend=False))\n",
    "        fig.add_traces(px.line(df, x=\"Time\", y=\"Average Age\", color=\"Agent\").data)\n",
    "        fig.for_each_trace(lambda trace: trace.update(y=trace.y / 60))\n",
    "        fig.for_each_yaxis(lambda axis: axis.update(title=f\"Age (min)\"))\n",
    "        fig.update_yaxes(tickformat=\".3s\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No data storage data.\")\n",
    "else:\n",
    "    print(\"No data analysis performed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
